{
    "collab_server" : "",
    "contents" : "---\ntitle: \"article-sql-odbc\"\noutput: word_document\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n```\n\n\n\n# Analysing data in SQL Server 16, combining R and SQL\n\n## Overview\n\nR is the most popular programming language for statistics and machine learning, and SQL is the lingua franca for the data manipulation. Dealing with an advanced analytics scenario, we need to pre-process the data and to build machine learning models. A good solution consists in using each tool for the purpose it’s designed for: the standard data preparation using a tool supporting SQL, the custom data preparation and the machine learning models using R. \n\n**SQL Server 2016** has the option to include an extension: **Microsoft R Services**. It’s based on **MRS** (Microsoft R Server), a tool designed by Revolution Analytics to scale R across large data volumes. In SQL Server 2016, R Services provides a direct interface between MRS and the SQL databases. In this way, it’s possible to analyse the SQL tables and to create new tables using the MRS tools. In addition, the R package *RODBC* allows to run SQL queries from R. \n\nThis article shows a simple example integrating R and SQL. To follow all the steps, some prior knowledge about the basic R functions is required.\n\n## Setting-up the environment\n\nIn this article, we are using a SQL Server 2016 VM. To set-up the environment, the steps are\n\n1.\tLog-in to Azure and set-up a SQL Server machine with R Services. To install R Services, refer to this: https://msdn.microsoft.com/en-us/library/mt696069.aspx \n2.\tConnect to SQL Server: from the Windows task bar, open SQL Server Management Studio and connect to it using your credentials.\n3.\t Create a new database: right-click on Databases and choose *New Database…*.\n \n4.\tGive a name to the new database, e.g. *iristest*. Then, click on *Add* and *OK*.\n \n5.\tOpen the query editor: right-click on the new database and choose *New Query*.\n \n6.\tDefine the credentials to authenticate to the database: in the editor, paste and run the following query. You should replace the parameter *testiris* with the name of your database, and username and password with new credentials to access this database.\n\n```{sql}\nUSE [testiris]\nGO\nCREATE LOGIN [username] WITH PASSWORD='password', CHECK_EXPIRATION=OFF,\nCHECK_POLICY=OFF;\nCREATE USER [username] FOR LOGIN [username] WITH DEFAULT_SCHEMA=[db_datareader]\nALTER ROLE [db_datareader] ADD MEMBER [username]\nALTER ROLE [db_ddladmin] ADD MEMBER [username]\n```\n\n7.\tBuild a new RStudio or Visual Studio project and create a new R script. See https://www.rstudio.com/products/RStudio/\n\n8.\tDefine a list with the parameters to connect to the database. They should be the same as in the previous SQL query.\n\n```{r}\nsql_par <- list(\n  Driver = \"SQL Server\",\n  Server = \".\",\n  Database = \"testiris\",\n  Uid = \"username\",\n  Pwd = \"password\"\n)\n\n```\n\n9.\tStarting from the list of parameters, define a connection string for the SQL database. For this purpose, you can use the function paste.\n\n\n```{r}\nsql_connect <- paste(names(sql_par), unlist(sql_par), \n                     sep = \"=\", collapse = \";\")\n```\n\n10.\tDefine a MRS data source object containing the information to access the *iristest* database. The inputs are the table name, e.g. *iris*, and the connection string.\n\n\n```{r eval=FALSE}\ntable_iris <- \"iris\"\nsql_iris <- RxSqlServerData(connectionString = sql_connect,\n                            table = table_iris)\n```\n\n```{r echo=FALSE}\ntable_iris <- \"iris\"\nsql_iris <- RxXdfData(\"iris.xdf\")\n```\n\n11.\tImport the data into a SQL table. For this purpose, we can use *rxDataStep*. Its inputs are the local dataframe *iris*, the data source object *sql_iris*, and *overwrite = TRUE*, specifying that we are overwriting the table if existing already. To avoid issues in the SQL queries, we also re-name the columns of iris, replacing the *.* with an *_*.\n\n\n```{r}\nnames(iris) <- gsub(\"[.]\", \"_\", names(iris))\nrxDataStep(iris, sql_iris, overwrite = TRUE)\n```\n\n12.\tInstall and load the package *RODBC* and initialise it using the connection string. We define the object channel containing the information to access the database.\n\n\n```{r eval=FALSE}\nlibrary(RODBC)\nchannel <- RODBC::odbcDriverConnect(sql_connect)\n```\n\n\n\n## Exploring the data\n\nTo explore the data, we can either use MRS or SQL. In MRS, there is the option to quickly access the metadata using *rxGetVarInfo*.\n\n```{r}\nrxGetVarInfo(sql_iris)\n```\n\nThe output contains the name and type of each field. Also, it’s possible to compute a quick summary of the table using *rxSummary*. The inputs are\n\n-\t*Formula*: what variables we want to summarise, using the formula syntax. For more info about the formula, have a look at the related material typing *?formula* into the R console. To include all the variables, we can use *.*.\n-\t*Data*: the data source object, containing the information to access the data.\n\n```{r}\nsummary_iris <- rxSummary(~ ., sql_iris)\nsummary_iris$sDataFrame\n```\n\nThis summary contains some basic statistics like the mean and the standard deviation.\n\nUsing *RODBC*, we can run any SQL query. The inputs are the connection object *channel*, defined previously, and the query string. Let’s see a simple example.\n\n```{r eval=FALSE}\nRODBC::sqlQuery(channel, \"select count(*) from iris\")\n```\n\nAs expected, the output is the number of records.\n\nR contains good string manipulation tools that allow us to build complex queries and to write extensions. To show the approach, we perform a simple group by operation. The steps are\n\n1.\tDefine the skeleton of the query, leaving the column names as *%s* parameters\n2.\tDefine the parameters\n3.\tDefine the query inclusive of its parameters using *sprintf*\n4.\tRun the query\n\nThe R code is\n\n```{r eval=FALSE}\nquery_sql <- \"select %s, avg(%s) as avg_sl from iris group by %s\"\ncol_group <- \"Species\"\ncol_value <- \"Sepal_Length\"\nquery_count <- sprintf(query_sql, col_group, col_value, col_group)\ndf_avg_value <- RODBC::sqlQuery(channel, query_count)\ndf_avg_value\n```\n\n```{r echo=FALSE}\nlibrary(dplyr)\ndf_avg_value <- iris %>%\n  dplyr::group_by(Species) %>%\n  dplyr::summarise(avg_sl = mean(Sepal_Length)) %>%\n  data.frame()\ndf_avg_value\n```\n\nUsing a similar approach, we can define more complex queries. Also, if we need to run similar queries many times, it’s possible to build R functions that build the query depending on some given parameters.\n\n\n\n## Processing the data\n\nTo process the data, it’s possible to use both MRS and SQL.\nWith MRS, we can process the data using the function rxDataStep. This function allows to build custom data processing operations. A simple example consists in defining a new column Sepal.Size with simple maths operations. The steps are\n\n1.\tDefine a new SQL data source object\n2.\tDefine the SQL table using *RxSqlServerData*. Its arguments are the input and output data object, and *overwrite = TRUE*, similarly to before. In addition, we define the new column using the transforms input.\n3.\tHave a look at the new table using *rxGetVarInfo*\n\nThis is the code:\n\n```{r eval=FALSE}\ntable_iris_2 <- \"iris2\"\nsql_iris_2 <- RxSqlServerData(connectionString = sql_connect,\n                            table = table_iris_2)\nrxDataStep(inData = sql_iris, \n           outFile = sql_iris_2, \n           transforms = list(Sepal.Size = Sepal.Length * Sepal.Width),\n           overwrite = TRUE)\nrxGetVarInfo(sql_iris_2)\n```\n\n```{r echo=FALSE}\ntable_iris_2 <- \"iris2\"\nsql_iris_2 <- RxXdfData(\"iris2.xdf\")\nrxDataStep(inData = sql_iris, \n           outFile = sql_iris_2, \n           transforms = list(Sepal_Size = Sepal_Length * Sepal_Width),\n           overwrite = TRUE)\nrxGetVarInfo(sql_iris_2)\n```\n\nAs expected, we have a new column: *Sepal_Size*.\n\nUsing the same approach, it’s possible to build complex custom operations, making use of the open-source R functions.\n\nUsing *RODBC*, it’s possible to run an SQL query defining a new table. For instance, we can join two tables. Using an approach similar to the previous SQL query, we build the related string and execute it using *RODBC*.\n\n```{r eval=FALSE}\ntable_avg_value <- \"avg_value\"\nsql_avg_value <- RxSqlServerData(connectionString = sql_connect,\n                                 table = table_avg_value)\n```\n\n```{r echo=FALSE}\ntable_avg_value <- \"avg_value\"\nsql_avg_value <- RxXdfData(\"avg_value.xdf\")\n```\n\n```{r eval=FALSE}\nrxDataStep(df_avg_value, sql_avg_value, overwrite = TRUE)\nquery_join <- \"select Sepal_Length, Species from iris\n                left join avg_value\n                on iris.Species = avg_value.Species\"\ndf_join <- RODBC::sqlQuery(channel, query_join)\ndf_join <- df_join[, c(\"Sepal_Length\", \"Species\", \"avg_sl\")]\nhead(df_join)\n```\n\n```{r echo=FALSE}\ndf_join <- iris %>%\n  dplyr::select(Sepal_Length, Species) %>%\n  dplyr::left_join(df_avg_value)\nhead(df_join)\n```\n\nAfter having processed the data, it’s possible to build machine learning models starting from the SQL tables. In this way, we don’t need to pull the data in-memory and we can deal with a large data volume. For instance, to build a linear regression, we can use *rxLinMod*. Similarly to *rxSummary*, the arguments are formula, defining the variables to include, and data, defining the data source. After having built the model, we can explore is using *summary*, similarly to open-source R.\n\n```{r}\nmodel_lm <- rxLinMod(formula = Petal_Length ~ Sepal_Length + Petal_Width,\n                     data = sql_iris)\nsummary(model_lm)\n```\n\nThe output is the same as using open-source R function *lm*.  The difference is that we can apply this function on a large table without needing to pull it in-memory.\n\n## Conclusions\n\nSQL and MRS are designed for different purposes. Having them into the same environment, it’s possible to use each of them in the most proper context: SQL to prepare the data, MRS to build advanced machine learning models. Also, the string manipulation tools provided by R allow to build SQL queries, making it possible to write code extensions. Another option is to include R code within the SQL queries although we haven’t dealt with that in this article.\n",
    "created" : 1469395060569.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2462638918",
    "id" : "5AB1B52",
    "lastKnownWriteTime" : 1469397625,
    "last_content_update" : 1469397625250,
    "path" : "~/1_docs_microsoft/3_docs_projects/3_docs_articles/article_odbc/article-odbc.Rmd",
    "project_path" : "article-odbc.Rmd",
    "properties" : {
        "tempName" : "Untitled2"
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}