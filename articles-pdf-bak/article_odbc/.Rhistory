sql_connect <- paste(names(sql_par), unlist(sql_par),
sep = "=", collapse = ";")
```
10.	Define a MRS data source object containing the information to access the iristest database. The inputs are the table name, e.g. iris, and the connection string.
```{r eval=FALSE}
table_iris <- "iris"
sql_iris <- RxSqlServerData(connectionString = sql_connect,
table = table_iris)
```
```{r echo=FALSE}
table_iris <- "iris"
sql_iris <- RxXdfData("iris.xdf")
```
11.	Import the data into a SQL table. For this purpose, we can use rxDataStep. Its inputs are the local dataframe iris, the data source object sql_iris, and overwrite = TRUE, specifying that we are overwriting the table if existing already. To avoid issues in the SQL queries, we also re-name the columns of iris, replacing the “.” with an “_”.
```{r}
names(iris) <- gsub("[.]", "_", names(iris))
rxDataStep(iris, sql_iris, overwrite = TRUE)
```
12.	Install and load the package RODBC and initialise it using the connection string. We define the object channel containing the information to access the database.
```{r}
# library(RODBC)
# channel <- RODBC::odbcDriverConnect(sql_connect)
```
## Exploring the data
To explore the data, we can either use MRS or SQL. In MRS, there is the option to quickly access the metadata using rxGetVarInfo.
```{r}
rxGetVarInfo(sql_iris)
```
The output contains the name and type of each field.
Also, it’s possible to compute a quick summary of the table using rxSummary. The inputs are
-	Formula: what variables we want to summarise, using the formula syntax. For more info about the formula, have a look at the related material typing ?formula into the R console. To include all the variables, we can use “.”.
-	Data: the data source object, containing the information to access the data.
```{r}
summary_iris <- rxSummary(~ ., sql_iris)
summary_iris$sDataFrame
```
This summary contains some basic statistics like the mean and the standard deviation.
Using RODBC, we can run any SQL query. The inputs are the connection object channel, defined previously, and the query string. Let’s see a simple example.
```{r}
# RODBC::sqlQuery(channel, "select count(*) from iris")
```
As expected, the output is the number of records.
R contains good string manipulation tools that allow us to build complex queries and to write extensions. To show the approach, we perform a simple group by operation. The steps are
1.	Define the skeleton of the query, leaving the column names as %s parameters
2.	Define the parameters
3.	Define the query inclusive of its parameters using sprintf
4.	Run the query
The R code is
```{r}
query_sql <- "select %s, avg(%s) as avg_sl from iris group by %s"
col_group <- "Species"
col_value <- "Sepal_Length"
query_sql <- sprintf(query_sql, col_group, col_value, col_group)
# df_avg_value <- RODBC::sqlQuery(channel, query_sql)
# df_avg_value
```
Using a similar approach, we can define more complex queries. Also, if we need to run similar queries many times, it’s possible to build R functions that build the query depending on some given parameters.
## Processing the data
To process the data, it’s possible to use both MRS and SQL.
With MRS, we can process the data using the function rxDataStep. This function allows to build custom data processing operations. A simple example consists in defining a new column Sepal.Size with simple maths operations. The steps are
1.	Define a new SQL data source object
2.	Define the SQL table using RxSqlServerData. Its arguments are the input and output data object, and overwrite = TRUE, similarly to before. In addition, we define the new column using the transforms input.
3.	Have a look at the new table using rxGetVarInfo
```{r eval=FALSE}
table_iris_2 <- "iris2"
sql_iris_2 <- RxSqlServerData(connectionString = sql_connect,
table = table_iris_2)
rxDataStep(inData = sql_iris,
outFile = sql_iris_2,
transforms = list(Sepal.Size = Sepal.Length * Sepal.Width),
overwrite = TRUE)
rxGetVarInfo(sql_iris_2)
```
```{r echo=FALSE}
table_iris_2 <- "iris2"
sql_iris_2 <- RxXdfData("iris2.xdf")
rxDataStep(inData = sql_iris,
outFile = sql_iris_2,
transforms = list(Sepal_Size = Sepal_Length * Sepal_Width),
overwrite = TRUE)
rxGetVarInfo(sql_iris_2)
```
As expected, we have a new column: Sepal_Size.
Using the same approach, it’s possible to build complex custom operations, making use of the open-source R functions.
Using RODBC, it’s possible to run an SQL query defining a new table. For instance, we can join two tables. Using an approach similar to the previous SQL query, we build the related string and execute it using RODBC.
```{r}
table_avg_value <- "avg_value"
sql_avg_value <- RxSqlServerData(connectionString = sql_connect,
table = table_avg_value)
rxDataStep(df_avg_value, sql_avg_value, overwrite = TRUE)
query_join <- "select * from iris
left join avg_value
on iris.Species = avg_value.Species"
df_join <- RODBC::sqlQuery(channel, query_join)
head(df_join)
```
After having processed the data, it’s possible to build machine learning models starting from the SQL tables. In this way, we don’t need to pull the data in-memory and we can deal with a large data volume. For instance, to build a linear regression, we can use rxLinMod. Similarly to rxSummary, the arguments are formula, defining the variables to include, and data, defining the data source. After having built the model, we can explore is using summary, similarly to open-source R.
```{r}
model_lm <- rxLinMod(formula = Petal_Length ~ Sepal_Length + Petal_Width,
data = sql_iris)
summary(model_lm)
```
The output is the same as using open-source R function lm.  The difference is that we can apply this function on a large table without needing to pull it in-memory.
Conclusions
SQL and MRS are designed for different purposes. Having them into the same environment, it’s possible to use each of them in the most proper context: SQL to prepare the data, MRS to build advanced machine learning models. Also, the string manipulation tools provided by R allow to build SQL queries, making it possible to write code extensions. Another option is to include R code within the SQL queries although we haven’t dealt with that in this article.
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
sql_par <- list(
Driver = "SQL Server",
Server = ".",
Database = "testiris",
Uid = "username",
Pwd = "password"
)
# Chunk 3
sql_connect <- paste(names(sql_par), unlist(sql_par),
sep = "=", collapse = ";")
# Chunk 5
table_iris <- "iris"
sql_iris <- RxXdfData("iris.xdf")
# Chunk 6
names(iris) <- gsub("[.]", "_", names(iris))
rxDataStep(iris, sql_iris, overwrite = TRUE)
# Chunk 7
# library(RODBC)
# channel <- RODBC::odbcDriverConnect(sql_connect)
# Chunk 8
rxGetVarInfo(sql_iris)
# Chunk 9
summary_iris <- rxSummary(~ ., sql_iris)
summary_iris$sDataFrame
# Chunk 10
# RODBC::sqlQuery(channel, "select count(*) from iris")
# Chunk 11
query_sql <- "select %s, avg(%s) as avg_sl from iris group by %s"
col_group <- "Species"
col_value <- "Sepal_Length"
query_sql <- sprintf(query_sql, col_group, col_value, col_group)
# df_avg_value <- RODBC::sqlQuery(channel, query_sql)
# df_avg_value
# Chunk 13
table_iris_2 <- "iris2"
sql_iris_2 <- RxXdfData("iris2.xdf")
rxDataStep(inData = sql_iris,
outFile = sql_iris_2,
transforms = list(Sepal_Size = Sepal_Length * Sepal_Width),
overwrite = TRUE)
rxGetVarInfo(sql_iris_2)
# Chunk 15
table_avg_value <- "avg_value"
sql_avg_value <- RxXdfData("avg_value.xdf")
# Chunk 16
rxDataStep(df_avg_value, sql_avg_value, overwrite = TRUE)
query_join <- "select * from iris
left join avg_value
on iris.Species = avg_value.Species"
# df_join <- RODBC::sqlQuery(channel, query_join)
# head(df_join)
# Chunk 17
model_lm <- rxLinMod(formula = Petal_Length ~ Sepal_Length + Petal_Width,
data = sql_iris)
summary(model_lm)
df_avg_value
df_avg_value
---
title: "article-sql-odbc"
output: word_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Analysing data in SQL Server 16, combining R and SQL
## Overview
R is the most popular programming language for statistics and machine learning, and SQL is the lingua franca for the data manipulation. Dealing with an advanced analytics scenario, we need to pre-process the data and to build machine learning models. A good solution consists in using each tool for the purpose it’s designed for: the standard data preparation using a tool supporting SQL, the custom data preparation and the machine learning models using R.
SQL Server 2016 has the option to include an extension: Microsoft R Services. It’s based on MRS (Microsoft R Server), a tool designed by Revolution Analytics to scale R across large data volumes. In SQL Server 2016, R Services provides a direct interface between MRS and the SQL databases. In this way, it’s possible to analyse the SQL tables and to create new tables using the MRS tools. In addition, the R package RODBC allows to run SQL queries from R.
This article shows a simple example integrating R and SQL. To follow all the steps, some prior knowledge about the basic R functions is required.
Setting-up the environment
In this article, we are using a SQL Server 2016 VM. To set-up the environment, the steps are
1.	Log-in to Azure and set-up a SQL Server machine with R Services. To install R Services, refer to this: https://msdn.microsoft.com/en-us/library/mt696069.aspx
2.	Connect to SQL Server: from the Windows task bar, open SQL Server Management Studio and connect to it using your credentials.
3.	 Create a new database: right-click on Databases and choose “New Database…”.
4.	Give a name to the new database, e.g. iristest. Then, click on Add and OK.
5.	Open the query editor: right-click on the new database and choose “New Query”.
6.	Define the credentials to authenticate to the database: in the editor, paste and run the following query. You should replace the parameter testiris with the name of your database, and username and password with new credentials to access this database.
```{sql}
USE [testiris]
GO
CREATE LOGIN [username] WITH PASSWORD='password', CHECK_EXPIRATION=OFF,
CHECK_POLICY=OFF;
CREATE USER [username] FOR LOGIN [username] WITH DEFAULT_SCHEMA=[db_datareader]
ALTER ROLE [db_datareader] ADD MEMBER [username]
ALTER ROLE [db_ddladmin] ADD MEMBER [username]
```
7.	Build a new RStudio or Visual Studio project and create a new R script. See https://www.rstudio.com/products/RStudio/
8.	Define a list with the parameters to connect to the database. They should be the same as in the previous SQL query.
```{r}
sql_par <- list(
Driver = "SQL Server",
Server = ".",
Database = "testiris",
Uid = "username",
Pwd = "password"
)
```
9.	Starting from the list of parameters, define a connection string for the SQL database. For this purpose, you can use the function paste.
```{r}
sql_connect <- paste(names(sql_par), unlist(sql_par),
sep = "=", collapse = ";")
```
10.	Define a MRS data source object containing the information to access the iristest database. The inputs are the table name, e.g. iris, and the connection string.
```{r eval=FALSE}
table_iris <- "iris"
sql_iris <- RxSqlServerData(connectionString = sql_connect,
table = table_iris)
```
```{r echo=FALSE}
table_iris <- "iris"
sql_iris <- RxXdfData("iris.xdf")
```
11.	Import the data into a SQL table. For this purpose, we can use rxDataStep. Its inputs are the local dataframe iris, the data source object sql_iris, and overwrite = TRUE, specifying that we are overwriting the table if existing already. To avoid issues in the SQL queries, we also re-name the columns of iris, replacing the “.” with an “_”.
```{r}
names(iris) <- gsub("[.]", "_", names(iris))
rxDataStep(iris, sql_iris, overwrite = TRUE)
```
12.	Install and load the package RODBC and initialise it using the connection string. We define the object channel containing the information to access the database.
```{r}
# library(RODBC)
# channel <- RODBC::odbcDriverConnect(sql_connect)
```
## Exploring the data
To explore the data, we can either use MRS or SQL. In MRS, there is the option to quickly access the metadata using rxGetVarInfo.
```{r}
rxGetVarInfo(sql_iris)
```
The output contains the name and type of each field.
Also, it’s possible to compute a quick summary of the table using rxSummary. The inputs are
-	Formula: what variables we want to summarise, using the formula syntax. For more info about the formula, have a look at the related material typing ?formula into the R console. To include all the variables, we can use “.”.
-	Data: the data source object, containing the information to access the data.
```{r}
summary_iris <- rxSummary(~ ., sql_iris)
summary_iris$sDataFrame
```
This summary contains some basic statistics like the mean and the standard deviation.
Using RODBC, we can run any SQL query. The inputs are the connection object channel, defined previously, and the query string. Let’s see a simple example.
```{r}
# RODBC::sqlQuery(channel, "select count(*) from iris")
```
As expected, the output is the number of records.
R contains good string manipulation tools that allow us to build complex queries and to write extensions. To show the approach, we perform a simple group by operation. The steps are
1.	Define the skeleton of the query, leaving the column names as %s parameters
2.	Define the parameters
3.	Define the query inclusive of its parameters using sprintf
4.	Run the query
The R code is
```{r}
query_sql <- "select %s, avg(%s) as avg_sl from iris group by %s"
col_group <- "Species"
col_value <- "Sepal_Length"
query_sql <- sprintf(query_sql, col_group, col_value, col_group)
# df_avg_value <- RODBC::sqlQuery(channel, query_sql)
# df_avg_value
```
Using a similar approach, we can define more complex queries. Also, if we need to run similar queries many times, it’s possible to build R functions that build the query depending on some given parameters.
## Processing the data
To process the data, it’s possible to use both MRS and SQL.
With MRS, we can process the data using the function rxDataStep. This function allows to build custom data processing operations. A simple example consists in defining a new column Sepal.Size with simple maths operations. The steps are
1.	Define a new SQL data source object
2.	Define the SQL table using RxSqlServerData. Its arguments are the input and output data object, and overwrite = TRUE, similarly to before. In addition, we define the new column using the transforms input.
3.	Have a look at the new table using rxGetVarInfo
```{r eval=FALSE}
table_iris_2 <- "iris2"
sql_iris_2 <- RxSqlServerData(connectionString = sql_connect,
table = table_iris_2)
rxDataStep(inData = sql_iris,
outFile = sql_iris_2,
transforms = list(Sepal.Size = Sepal.Length * Sepal.Width),
overwrite = TRUE)
rxGetVarInfo(sql_iris_2)
```
```{r echo=FALSE}
table_iris_2 <- "iris2"
sql_iris_2 <- RxXdfData("iris2.xdf")
rxDataStep(inData = sql_iris,
outFile = sql_iris_2,
transforms = list(Sepal_Size = Sepal_Length * Sepal_Width),
overwrite = TRUE)
rxGetVarInfo(sql_iris_2)
```
As expected, we have a new column: Sepal_Size.
Using the same approach, it’s possible to build complex custom operations, making use of the open-source R functions.
Using RODBC, it’s possible to run an SQL query defining a new table. For instance, we can join two tables. Using an approach similar to the previous SQL query, we build the related string and execute it using RODBC.
```{r eval=FALSE}
table_avg_value <- "avg_value"
sql_avg_value <- RxSqlServerData(connectionString = sql_connect,
table = table_avg_value)
```
```{r echo=FALSE}
table_avg_value <- "avg_value"
sql_avg_value <- RxXdfData("avg_value.xdf")
```
```{r}
rxDataStep(df_avg_value, sql_avg_value, overwrite = TRUE)
query_join <- "select * from iris
left join avg_value
on iris.Species = avg_value.Species"
# df_join <- RODBC::sqlQuery(channel, query_join)
# head(df_join)
```
After having processed the data, it’s possible to build machine learning models starting from the SQL tables. In this way, we don’t need to pull the data in-memory and we can deal with a large data volume. For instance, to build a linear regression, we can use rxLinMod. Similarly to rxSummary, the arguments are formula, defining the variables to include, and data, defining the data source. After having built the model, we can explore is using summary, similarly to open-source R.
```{r}
model_lm <- rxLinMod(formula = Petal_Length ~ Sepal_Length + Petal_Width,
data = sql_iris)
summary(model_lm)
```
The output is the same as using open-source R function lm.  The difference is that we can apply this function on a large table without needing to pull it in-memory.
Conclusions
SQL and MRS are designed for different purposes. Having them into the same environment, it’s possible to use each of them in the most proper context: SQL to prepare the data, MRS to build advanced machine learning models. Also, the string manipulation tools provided by R allow to build SQL queries, making it possible to write code extensions. Another option is to include R code within the SQL queries although we haven’t dealt with that in this article.
on iris.Species = avg_value.Species"
table_avg_value
sql_avg_value <- RxXdfData("avg_value.xdf")
df_avg_value
---
title: "article-sql-odbc"
output: word_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Analysing data in SQL Server 16, combining R and SQL
## Overview
R is the most popular programming language for statistics and machine learning, and SQL is the lingua franca for the data manipulation. Dealing with an advanced analytics scenario, we need to pre-process the data and to build machine learning models. A good solution consists in using each tool for the purpose it’s designed for: the standard data preparation using a tool supporting SQL, the custom data preparation and the machine learning models using R.
**SQL Server 2016** has the option to include an extension: **Microsoft R Services**. It’s based on **MRS** (Microsoft R Server), a tool designed by Revolution Analytics to scale R across large data volumes. In SQL Server 2016, R Services provides a direct interface between MRS and the SQL databases. In this way, it’s possible to analyse the SQL tables and to create new tables using the MRS tools. In addition, the R package *RODBC* allows to run SQL queries from R.
This article shows a simple example integrating R and SQL. To follow all the steps, some prior knowledge about the basic R functions is required.
## Setting-up the environment
In this article, we are using a SQL Server 2016 VM. To set-up the environment, the steps are
1.	Log-in to Azure and set-up a SQL Server machine with R Services. To install R Services, refer to this: https://msdn.microsoft.com/en-us/library/mt696069.aspx
2.	Connect to SQL Server: from the Windows task bar, open SQL Server Management Studio and connect to it using your credentials.
3.	 Create a new database: right-click on Databases and choose *New Database…*.
4.	Give a name to the new database, e.g. *iristest*. Then, click on *Add* and *OK*.
5.	Open the query editor: right-click on the new database and choose *New Query*.
6.	Define the credentials to authenticate to the database: in the editor, paste and run the following query. You should replace the parameter *testiris* with the name of your database, and username and password with new credentials to access this database.
```{sql}
USE [testiris]
GO
CREATE LOGIN [username] WITH PASSWORD='password', CHECK_EXPIRATION=OFF,
CHECK_POLICY=OFF;
CREATE USER [username] FOR LOGIN [username] WITH DEFAULT_SCHEMA=[db_datareader]
ALTER ROLE [db_datareader] ADD MEMBER [username]
ALTER ROLE [db_ddladmin] ADD MEMBER [username]
```
7.	Build a new RStudio or Visual Studio project and create a new R script. See https://www.rstudio.com/products/RStudio/
8.	Define a list with the parameters to connect to the database. They should be the same as in the previous SQL query.
```{r}
sql_par <- list(
Driver = "SQL Server",
Server = ".",
Database = "testiris",
Uid = "username",
Pwd = "password"
)
```
9.	Starting from the list of parameters, define a connection string for the SQL database. For this purpose, you can use the function paste.
```{r}
sql_connect <- paste(names(sql_par), unlist(sql_par),
sep = "=", collapse = ";")
```
10.	Define a MRS data source object containing the information to access the *iristest* database. The inputs are the table name, e.g. *iris*, and the connection string.
```{r eval=FALSE}
table_iris <- "iris"
sql_iris <- RxSqlServerData(connectionString = sql_connect,
table = table_iris)
```
```{r echo=FALSE}
table_iris <- "iris"
sql_iris <- RxXdfData("iris.xdf")
```
11.	Import the data into a SQL table. For this purpose, we can use *rxDataStep*. Its inputs are the local dataframe *iris*, the data source object *sql_iris*, and *overwrite = TRUE*, specifying that we are overwriting the table if existing already. To avoid issues in the SQL queries, we also re-name the columns of iris, replacing the *.* with an *_*.
```{r}
names(iris) <- gsub("[.]", "_", names(iris))
rxDataStep(iris, sql_iris, overwrite = TRUE)
```
12.	Install and load the package *RODBC* and initialise it using the connection string. We define the object channel containing the information to access the database.
```{r}
# library(RODBC)
# channel <- RODBC::odbcDriverConnect(sql_connect)
```
## Exploring the data
To explore the data, we can either use MRS or SQL. In MRS, there is the option to quickly access the metadata using *rxGetVarInfo*.
```{r}
rxGetVarInfo(sql_iris)
```
The output contains the name and type of each field. Also, it’s possible to compute a quick summary of the table using *rxSummary*. The inputs are
-	*Formula*: what variables we want to summarise, using the formula syntax. For more info about the formula, have a look at the related material typing *?formula* into the R console. To include all the variables, we can use *.*.
-	*Data*: the data source object, containing the information to access the data.
```{r}
summary_iris <- rxSummary(~ ., sql_iris)
summary_iris$sDataFrame
```
This summary contains some basic statistics like the mean and the standard deviation.
Using *RODBC*, we can run any SQL query. The inputs are the connection object *channel*, defined previously, and the query string. Let’s see a simple example.
```{r}
# RODBC::sqlQuery(channel, "select count(*) from iris")
```
As expected, the output is the number of records.
R contains good string manipulation tools that allow us to build complex queries and to write extensions. To show the approach, we perform a simple group by operation. The steps are
1.	Define the skeleton of the query, leaving the column names as *%s* parameters
2.	Define the parameters
3.	Define the query inclusive of its parameters using *sprintf*
4.	Run the query
The R code is
```{r}
query_sql <- "select %s, avg(%s) as avg_sl from iris group by %s"
col_group <- "Species"
col_value <- "Sepal_Length"
query_sql <- sprintf(query_sql, col_group, col_value, col_group)
# df_avg_value <- RODBC::sqlQuery(channel, query_sql)
# df_avg_value
```
Using a similar approach, we can define more complex queries. Also, if we need to run similar queries many times, it’s possible to build R functions that build the query depending on some given parameters.
## Processing the data
To process the data, it’s possible to use both MRS and SQL.
With MRS, we can process the data using the function rxDataStep. This function allows to build custom data processing operations. A simple example consists in defining a new column Sepal.Size with simple maths operations. The steps are
1.	Define a new SQL data source object
2.	Define the SQL table using *RxSqlServerData*. Its arguments are the input and output data object, and *overwrite = TRUE*, similarly to before. In addition, we define the new column using the transforms input.
3.	Have a look at the new table using *rxGetVarInfo*
This is the code:
```{r eval=FALSE}
table_iris_2 <- "iris2"
sql_iris_2 <- RxSqlServerData(connectionString = sql_connect,
table = table_iris_2)
rxDataStep(inData = sql_iris,
outFile = sql_iris_2,
transforms = list(Sepal.Size = Sepal.Length * Sepal.Width),
overwrite = TRUE)
rxGetVarInfo(sql_iris_2)
```
```{r echo=FALSE}
table_iris_2 <- "iris2"
sql_iris_2 <- RxXdfData("iris2.xdf")
rxDataStep(inData = sql_iris,
outFile = sql_iris_2,
transforms = list(Sepal_Size = Sepal_Length * Sepal_Width),
overwrite = TRUE)
rxGetVarInfo(sql_iris_2)
```
As expected, we have a new column: *Sepal_Size*.
Using the same approach, it’s possible to build complex custom operations, making use of the open-source R functions.
Using *RODBC*, it’s possible to run an SQL query defining a new table. For instance, we can join two tables. Using an approach similar to the previous SQL query, we build the related string and execute it using *RODBC*.
```{r eval=FALSE}
table_avg_value <- "avg_value"
sql_avg_value <- RxSqlServerData(connectionString = sql_connect,
table = table_avg_value)
```
```{r echo=FALSE}
table_avg_value <- "avg_value"
sql_avg_value <- RxXdfData("avg_value.xdf")
```
```{r}
# rxDataStep(df_avg_value, sql_avg_value, overwrite = TRUE)
query_join <- "select * from iris
left join avg_value
on iris.Species = avg_value.Species"
# df_join <- RODBC::sqlQuery(channel, query_join)
# head(df_join)
```
After having processed the data, it’s possible to build machine learning models starting from the SQL tables. In this way, we don’t need to pull the data in-memory and we can deal with a large data volume. For instance, to build a linear regression, we can use *rxLinMod*. Similarly to *rxSummary*, the arguments are formula, defining the variables to include, and data, defining the data source. After having built the model, we can explore is using *summary*, similarly to open-source R.
```{r}
model_lm <- rxLinMod(formula = Petal_Length ~ Sepal_Length + Petal_Width,
data = sql_iris)
summary(model_lm)
```
The output is the same as using open-source R function *lm*.  The difference is that we can apply this function on a large table without needing to pull it in-memory.
## Conclusions
SQL and MRS are designed for different purposes. Having them into the same environment, it’s possible to use each of them in the most proper context: SQL to prepare the data, MRS to build advanced machine learning models. Also, the string manipulation tools provided by R allow to build SQL queries, making it possible to write code extensions. Another option is to include R code within the SQL queries although we haven’t dealt with that in this article.
query_count <- sprintf(query_sql, col_group, col_value, col_group)
query_count
df_avg_value
library(dplyr)
query_count
iris %>%
dplyr::group_by(Species) %>%
dplyr::summarise(avg_sl = mean(Sepal.Length))
names(iris)
iris %>%
dplyr::group_by(Species) %>%
dplyr::summarise(avg_sl = mean(Sepal_Length))
query_count
iris %>%
dplyr::group_by(Species) %>%
dplyr::summarise(avg_sl = mean(Sepal_Length)) %>%
data.frame()
df_avg_value <- iris %>%
dplyr::group_by(Species) %>%
dplyr::summarise(avg_sl = mean(Sepal_Length)) %>%
data.frame()
df_avg_value
iris %>%
dplyr::left_join(df_avg_value)
df_join <- iris %>%
dplyr::left_join(df_avg_value)
head(df_join)
df_join <- iris %>%
dplyr::select(Sepal_Length, Species) %>%
dplyr::left_join(df_avg_value)
head(df_join)
df_join <- iris %>%
dplyr::select(Sepal_Length, Species) %>%
dplyr::left_join(df_avg_value)
head(df_join)
df_join <- df_join[, c("Sepal_Length", "Species", "avg_sl")]
head(df_join)
