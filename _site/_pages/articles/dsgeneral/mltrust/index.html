<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Can we trust machine learning products? - Personal blog</title>
<meta name="description" content="">


  <meta name="author" content="Michele Usuelli">
  


<meta property="og:type" content="website">
<meta property="og:locale" content="en_GB">
<meta property="og:site_name" content="Personal blog">
<meta property="og:title" content="Can we trust machine learning products?">
<meta property="og:url" content="http://localhost:4000/_pages/articles/dsgeneral/mltrust/">


  <meta property="og:description" content="">











  

  


<link rel="canonical" href="http://localhost:4000/_pages/articles/dsgeneral/mltrust/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Michele Usuelli",
      "url": "http://localhost:4000/"
    
  }
</script>







<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Personal blog Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--default">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          Personal blog
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/_pages/articles">Articles</a>
            </li><li class="masthead__menu-item">
              <a href="/_pages/books">Books</a>
            </li><li class="masthead__menu-item">
              <a href="/_pages/conferences">Conferences</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <blockquote class="indent markdown-content  ">
      <h1 id="can-we-trust-machine-learning-products">Can we trust machine learning products?</h1>

<p><strong>Why would we trust a machine learning product?</strong></p>

<p>Data science is already proven to solve relevant problem. But how about its application to our problems. Often, they involve either recommendations or automated actions. Can we really trust them?</p>

<p>This article focuses on predictive models although the same principles are true for other categories of techniques.</p>

<p>Example of use-cases handled by predictive models are</p>

<ul>
  <li><em>Predictive maintenance</em>: forecast the  breakdown and/or malfunctioning of machines to proactively fix them</li>
  <li><em>Credit scoring</em>: decide which customers are trustworthy enough to receive a loan so that the bank can be covered by a default risk</li>
  <li><em>Sales forecast</em>: predict the sales volume to optimize the inventory</li>
</ul>

<p><strong>The key of trust is transparency.</strong></p>

<p>To trust a system, the starting point is to fully understand it. What does that mean in the context of machine learning?</p>

<p>This article focuses on the following aspects</p>

<ul>
  <li>Traceability: where does the data come from?</li>
  <li>Interpretability: how does the predictive model use the data?</li>
  <li>Measurability: how much error are we expecting?</li>
  <li>Actionability: influence on the end use to perform a specific action</li>
</ul>

<p>Each aspect is covered by the related section.</p>

<h2 id="interpretability">Interpretability</h2>

<p>In our example, the outcome of the predictive models</p>

<p>Predictive models can foresee the breakdown of an engine, the credit score of a customer or the sales volume of a new product. In either case, how do we know if we can trust the outcome of a model? Also, does it comply to rules and follow ethical principles?</p>

<p>The starting point is the capability of explaining. Let’s start with simple example. We predict that an engine will break down because it’s running slower than usual. A bank customer doesn’t receive a loan because of a high debit on the credit card. The sales volume will raise because of a commercial promotion. Machine learning often utilizes a wider set of information and utilizes a more advanced logic. Still, we’re aiming to explain the rationale behind its outcome.</p>

<p>The starting point of machine learning models are data sources, so we can start tracking all the information being used. In this way, we can easily spot ethical issues and legislation incompliances. The next step is to identify which specific information is being used by the model and what is being discarded. Ultimately, applying the predictive model on the new data, the information being used is a specific subset.</p>

<p>Depending on the technique, the methodology might be different. It’s usually straightforward to explain tree-based models such as the decision forest, as shown by my article. Likewise, linear models can be easily explained. However, some techniques are too  complex to be explained, e.g. neural networks. In this case, even if the model is unexplainable, there are workarounds such as LIME and SHAP, showing what would have changed if the data differred.</p>

<h2 id="measurability">Measurability</h2>

<p>Let’s assume that a predictive model is already explainable. The thought process to define its outcome is fully transparent and we can track all the information being used. What will happen applying the model in a real-life situation? Will it be able to foresee future events accurately?</p>

<p>If we predict an engine breakdown, we want to know how many breakdowns we can predict and the number of false positives. Same is true for the credit risk. If we are predicting the sales volume, the metric would be the average error, whichever the “average” is defined.</p>

<p>Being able to assess the reliability and accuracy of the outcome of a model is a key. Clearly, it’s impossible to know  how a model will perform in the future. However, it’s possible to know how the same methodology would have performed in the past.</p>

<p>Predicting something that is already known is trivial. Therefore, a common pitfall it to “cheat”, either voluntarily or unvoluntarily. To prevent that, the key is to replicate the real life application. Some important aspects are to</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- separate training and test set entirely
- take into account the time: in most cases, we are predicting and event in time. A common pitfall is to predict the past utilizing future information
</code></pre></div></div>

<p>In addition, the outcome of the testing should reflect the broader context. Key aspects are</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- business focus: in addition to measuring the accuracy, are we also translating it into measurable business KPIs?
- benchmark: if we weren't utilizing a predictive model, by how much would the forecast be worse?
</code></pre></div></div>

<p>My colleague Ajay published a series of two articles, showing how to measure the performance of classification and regression models.</p>

<h2 id="actionability">Actionability</h2>

<p>Last but not least, even if we can explain and measure the outcome of a machine learning product, to have a tangible impact it has to trigger an action.</p>

<p>In the predictive maintenance scenario, the action is to either send an engineer to check the machine or to provide confidence that the machine doesn’t need any maintenance. In the loan use-case, the action is to either approve or reject the load. Predicting sales helps optimizing the production volume.</p>

<p>Prior to start experimenting and building the product, having in mind the end action helps define the direction of the project. After having delivered the product, keeping track of the actions and feedback allows to improve the product further.</p>

<p>Actionability applies to both interpretability and measurability:
	- Interpretability: knowing the root causes allows to define an action to fix them. Some root causes are actionable and some others are not. Knowing what can be changed is an enabler to define an action. For instance, in the predictive maintenance scenario, the action is to fix the root cause leading to a failure. If the root cause is having the last maintenance too far back in time, the solution is to send an engineer to maintain the machine
	- Measurability: the estimated error is as important as the prediction. Knowing the actions that can be taken enables the definition of an accuracy metric accordingly. In the sales forecast use-case, the accuracy metric might be related to the way the forecasting will be consumed.</p>

<p>Actionability is the starting point and the end point of most of the data science projects.</p>

<h2 id="conclusions">Conclusions</h2>

<p>This article covered interpretability, measurability and actionability, key aspects of each data science project. One remark is about other important topics, such as ethics, privacy and compliance, that will be enabled by these.</p>


    </blockquote>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
          <li><a href="https://www.linkedin.com/in/michele-usuelli-1b84b460/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-instagram" aria-hidden="true"></i> LinkedIn</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2023 Michele Usuelli. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>










  </body>
</html>
