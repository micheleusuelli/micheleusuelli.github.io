{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Scaling a recommender system across large data volumes\"\noutput: pdf_document\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n```\n\n## Building a recommendation engine in presence of large data volume\n\nE-commerce businesses can suggest new products to their customers. How do they choose the products to recommend? The companies collect data about the purchases of their customers. Starting from the purchase history, they can identify items that have been taken by the same customers and customers that bought the same items. Given a new customer, the company can recommend him/her items similar to the ones that he/she purchased already, or items that have been purchased by similar customers. The recommendations can also take account of other data sources like personal information, items descriptions, customer ratings and reviews. Large companies like Amazon and eBay already built sophisticated recommendation engines tailored to their environment. \n\nWhat if a smaller company wants to build a smaller recommendation engine from scratch? Even if the complexity is not the same as huge companies, the volume of data to process may be large. In this article, we see how to build simple recommender systems that are scalable across large data volumes. To show the concepts avoiding unnecessary complications, in this article we are using the information about purchases only. Due to the complexity of the problem and to the variety of contexts, this article describes it from a generic high-level perspective.\n\n\n\n## Choosing the environment\n\nIn this article, the technology that we use is SQL Server 2016 with R Services. The reason is that we can store large SQL tables and process them using advanced analytics techniques provided by R.\n\nThe use-case consists in recommending movies to the users. Given a set of movies and users, the table describes what movies each user has watched. To avoid further complications, the table doesnâ€™t include user ratings. Its structure is:\n\n-\tA row for each movie\n-\tA column for each user\n-\tCells equal to 1 if the user watched the movie and to 0 otherwise\n\nThe data has already been imported into SQL 2016 into a table called *movies*. To analyse the data, we use the R environment and we define a SQL table object called *sql_movies* that allows us to access the data. The function creating the object is *RxSqlServerData* and it needs a connection string for the database and the name of the table. We also define another SQL table object, called *sql_clust_users*, referring to a table that doesn't exist yet. We'll create and use this table from R.\n\n```{r echo=TRUE, eval=F}\nconnection_string <- \"Driver=SQL Server;Server=.;Database=movies;Uid=usernam;password\"\n\nsql_movies <- RxSqlServerData(connectionString = connection_string,\n                              table = \"movies\")\n\nsql_clust_users <- RxSqlServerData(connectionString = connection_string,\n                              table = \"sql_clust_users\")\n\n```\n\n```{r echo=F, eval=TRUE}\nsql_movies <- RxXdfData(\"sql_movies.xdf\")\nsql_clust_users <- RxXdfData(\"sql_clust_users.xdf\")\n```\n\nLet's have a quick look at the data.\n\n```{r echo=TRUE, eval=T}\ndim(sql_movies)\nrxGetVarInfo(sql_movies)[1:4]\nhead(sql_movies)[, 1:8]\n```\n\nThe table has 865 columns. The first column contains the Movie ID and each other column corresponds to a user. The values in the *user* columns are equal to 1 if the user watched the movie and to 0 otherwise.\n\nTo build a recommendation engine, we can use the R package *recommenderlab*. However, this package needs all the data to be stored into the RAM, so it can deal with relatively small data volumes. Therefore, to process a large dataset we need to reduce its volume. In this example, the data volume is not really huge. However, the solution is designed in such a way that it's applicable on a larger dataset.\n\n\n\n## Reducing the data volume\n\nTo produce a small table, we can either reduce the number of rows or the number of columns. In this chapter we are reducing both.\n\nA common challenge is that there are many users, i.e. columns. A solution consists in identifying small groups of similar users and defining a new table having a column for each group of users. The steps are\n\n1. Define a formula describing what columns we are dealing with. We include all the columns apart from the first\n2. Measure the similarity between users using the function rxCor\n3. Starting from the similarity, define a matrix containing the distance between the users\n4. Starting from the distance matrix, identify groups of similar users applying hierarchical clustering\n5. Define a new table which columns correspond to the clusters. The value of each column is equal to one if at least one user of the cluster watched the movie\n\nThe new table contains a row for each movie and a column for each group of users.\n\nThis is the related code to detect 100 clusters of users.\n\n```{r echo=TRUE, eval=TRUE}\n# define the formula\ncols_movies <- names(sql_movies)[-1]\nstring_users <- paste(cols_movies, collapse = \" + \")\nformula_users <- formula(paste(\"~\", string_users))\n\n# build the hierachical clustering model\ncor_users <- rxCor(formula_users, sql_movies,\n                   rowsPerRead = 5e02)\ndist_users <- as.dist(1 - abs(cor_users))\nmodel_hc <- hclust(dist_users, method = \"complete\")\nwhich_cluster <- cutree(model_hc, k = 100)\nvar_clusters <- sort(unique(which_cluster))\n\n# group the users into clusters\nclusterCols <- function(list_in) {\n  \n  # define a field for each cluster\n  list_out <- lapply(var_clusters, function(this_cluster) {\n    these_cols <- names(which_cluster[which_cluster == this_cluster])\n    df_cols <- data.frame(list_in[these_cols])\n    rowSums(df_cols) > 0\n  })\n  \n  names(list_out) <- paste0(\"clust\", var_clusters)\n  # for each movie, count the number of clusers having watched it\n  df_views <- data.frame(list_out)\n  list_out$n_views <- rowSums(df_views)\n  \n  # add the movie ID\n  list_out$MovieId <- list_in$MovieId\n  \n  list_out\n}\n\nrxDataStep(\n  inData = sql_movies,\n  outFile = sql_clust_users,\n  overwrite = TRUE,\n  transformFunc = clusterCols,\n  transformObjects = list(var_clusters = var_clusters,\n                          which_cluster = which_cluster))\n\ndim(sql_clust_users)\n```\n\n\nThe other approach to decrease the size is to reduce the number of rows. Applying a clustering algorithm, we can identify groups of similar items and define a table with a row for each group of items. For this purpose, we can use the function *rxKmeans*.\n\nThe starting point is *sql_clust_users* and the steps are\n\n1. Build a formula defining the variables to include into the clustering model\n2. Identify 20 clusters of movies using *rxKmeans*\n3. Extract the centers of the clusters. They contain averages that in this context express the percentage of users that watched each movie\n4. Starting from the centers, define the table *df_movies* which values are 1 if the percentage is above 10% and 0 otherwise\n\nThis is the related code.\n\n```{r echo=TRUE, eval=TRUE}\ncols_km <- names(sql_clust_users)\nfeat_km <- paste(cols_km, collapse = \" + \")\nformula_km <- formula(paste(\"~\", feat_km))\nmodel_km <- rxKmeans(formula_km, sql_clust_users,\n                     numClusters = 20,\n                     reportProgress = 0)\ndf_movies <- ifelse(model_km$centers[, -1] > 0.1, 1, 0)\ndf_movies[1:10, 1:6]\n```\n\nThe table *df_movies* is small-sized and it contains a column for each cluster of users and a row for each cluster of movies. The value of each cell is equal to 1 if the related cluster of users watched at least 10% of the related cluster of movies, and 0 otherwise.\n\n\n## Building the engine\n\nIn the previous step we produced a small table stored into the R environment. Starting from that, we can build a recommender system using the package *recommenderlab*.  \n\nThe steps are\n\n1. Starting from *df_movies*, build, test and validate a recommendation engine. There are a few options in the recommenderlab package, so a good approach is to test and evaluate a few of them, and to pick the best-performing\n2. Given a new user, measure the distance between each cluster center and he/she. Then, identify the closest center and associate the user to the related cluster\n3. Identify the cluster of movies to recommend to the cluster related to the new user\n4. Out of the recommended cluster of movies, choose one or more movies to recommend to the user\n\n\n## Conclusions\n\nUsing the approach described by this article, it's possible to apply a recommender system on a large data volume.\n\nTo extend this solution, it's possible to use a matrix containing user ratings instead of just 0s a 1s. To include some information about the users and/or movies, it's possible to summarise it for each cluster. Other adjustments can follow a similar methodology.\n\n\n\n",
    "created" : 1469200011945.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "126024892",
    "id" : "7E7E9977",
    "lastKnownWriteTime" : 1470216102,
    "last_content_update" : 1470216102419,
    "path" : "~/1_docs_microsoft/3_docs_projects/3_docs_articles/recommender_systems/article-recommendation.Rmd",
    "project_path" : "article-recommendation.Rmd",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}